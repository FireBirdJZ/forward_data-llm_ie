import os
import openai
import json
from concurrent.futures import ThreadPoolExecutor

import web_extractor

# Specify the path to config.json (adjust the path as needed)
config_file_path = '/Users/jasonz/forward_data_lab_llmie/forward_data-llm_ie/config.json'

with open(config_file_path, "r") as config_file:
    config = json.load(config_file)
    openai.api_key = config["api_key"]

def ExtractAndAppendToJSON(url: str, prompt: str, output_file: str) -> None:
    """
    Extracts information from a webpage and appends it to a JSON file.

    Args:
        url (str): The URL of the webpage to extract information from.
        output_file (str): The name of the JSON file to append to.

    Returns:
        None
    """
    # Extract text from the given URL using web_extractor
    extracted_text = web_extractor.ExtractTextFromWebpage(url)

    # Define the prompt for generating information
    prompt += extracted_text

    # Use the GPT-3 model to generate a response
    chat_completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    # Extract the message generated by the chat model
    chatbot_response = chat_completion['choices'][0]['message']['content']
    print("chatbot_response: ", chatbot_response)

    # Create a dictionary to store the extracted information
    # extracted_info = {
    #     "professor": url.split("/")[-1],  # Extract professor name from URL
    #     "information": json.loads(chatbot_response)  # Convert JSON string to dictionary
    # }

    # Append the extracted information to the JSON file with indentation
    with open(output_file, "a") as json_file:
        json.dump(json.loads(chatbot_response), json_file, indent=4)  # Add indentation for readability
        json_file.write("\n")  # Add a newline to separate entries

    print(f"Information appended to {output_file}")


# For Testing ExtractTextFromWebpage and ExtractTextFromWebpageTraf
if __name__ == "__main__":

    # Example usage of Professor Pages:
    cs_profs = ["jeffe", "vadve", "kcchang"]
    #url = f"https://cs.illinois.edu/about/people/faculty/{cs_profs[2]}"
    #chem_profs = ["mikaelb", "mdburke", "ggirolam"]
    #url = f"https://chemistry.illinois.edu/{chem_profs[2]}"
    output_file = "extracted_info.json"
    prof_prompt = ("From this professor, extract the Education, Research Interests, Email, and other important information "
        "from the text given and output in JSON FORMAT- ")

    shopify_names = ["ecommerce-seo-beginners-guide"]
    shopify_output_file = "shopify_extracted_info.json"
    shopify_prompt = ("You have to output your response in JSON format: Extract the steps shown in the blog on How to create an ecommerce SEO strategy- ")

    with ThreadPoolExecutor(max_workers=1) as executor:
        #for name in cs_profs:
        for name in shopify_names:
            #prof_url = f"https://cs.illinois.edu/about/people/faculty/{name}"
            shopify_url = f"https://www.shopify.com/blog/{name}"
            future = executor.submit(ExtractAndAppendToJSON, shopify_url, shopify_prompt, shopify_output_file)
            result = future.result()

        # if result:
        #     print(result)
        # else:
        #     print("Failed to Extract infromation and append to Json file.")
