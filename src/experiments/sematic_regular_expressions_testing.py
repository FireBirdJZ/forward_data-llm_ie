import openai
import subprocess
import json
import os

# Specify the path to config.json (adjust the path as needed)
config_file_path = '/Users/jasonz/forward_data_lab_llmie/forward_data-llm_ie/config.json'

with open(config_file_path, "r") as config_file:
    config = json.load(config_file)
    openai.api_key = config["api_key"]

def generate_python_code(prompt):
   # Use the GPT-3 model to generate a response
    chat_completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
    )

    # Extract the message generated by the chat model
    return chat_completion['choices'][0]['message']['content']

def save_and_run_code(code, directory):
    os.makedirs(directory, exist_ok=True)
    code_filename = os.path.join(directory, "generated_code.py")
    output_filename = os.path.join(directory, "output.txt")

    with open(code_filename, 'w') as code_file:
        code_file.write(code)
    try:
        result = subprocess.run(["python", code_filename], capture_output=True, text=True, check=True)
        with open(output_filename, 'w') as output_file:
            output_file.write(result.stdout)
    except subprocess.CalledProcessError as e:
        with open(output_filename, 'w') as output_file:
            output_file.write(e.stderr)

    return code_filename, output_filename

if __name__ == "__main__":
    chat_prompt = "Don't output anything in the prompt other than the code so it will run- Generate Python code to print every instance and the position in the text of the word Professor from this url:https://cs.illinois.edu/about/people/all-faculty"
    generated_code = generate_python_code(chat_prompt)

    output_dir = "generated_code_directory"  # Specify the directory name
    code_filename, output_filename = save_and_run_code(generated_code, output_dir)

    print("Generated Code and Output have been saved to the directory:")
    print(output_dir)
    print(f"Generated Code: {code_filename}")
    print(f"Output: {output_filename}")
